{"provider":"autogen_agentchat.teams.RoundRobinGroupChat","component_type":"team","version":1,"component_version":1,"description":"A team that runs a group chat with participants taking turns in a round-robin fashion\n    to publish a message to all.","label":"RoundRobinGroupChat","config":{"participants":[{"provider":"autogen_agentchat.agents.AssistantAgent","component_type":"agent","version":1,"component_version":1,"description":"An agent that provides assistance with tool use.","label":"AssistantAgent","config":{"name":"AnalystAssistant","model_client":{"provider":"autogen_ext.models.openai.OpenAIChatCompletionClient","component_type":"model","version":1,"component_version":1,"description":"Chat completion client for OpenAI hosted models.","label":"OpenAIChatCompletionClient","config":{"model":"gpt-4o-mini","api_key":"**********"}},"tools":[{"provider":"autogen_core.tools.FunctionTool","component_type":"tool","version":1,"component_version":1,"description":"Create custom tools by wrapping standard Python functions.","label":"FunctionTool","config":{"source_code":"async def process_group_alert(csv_url: str) -> str:\n    \"\"\"\n    Process alerts from the CSV file.\n\n    Args:\n        csv_url: URL or path to the CSV file\n\n    Returns:\n        Processing results summary\n    \"\"\"\n    from playwright.async_api import async_playwright\n    from io import BytesIO\n    import requests\n    import datetime\n    import logging\n    import pandas as pd\n    from typing import Tuple, Dict, List\n    from supabase import create_client, Client\n    import json\n    import os\n    import re\n\n    proxy_server = \"pr.rampageproxies.com:8888\"\n    proxy_username = \"xdsmbKbB-cc-ch-pool-rampagecore\"\n    proxy_password = \"FZeZSSFc\"\n\n    class SupabaseStorage:\n        def __init__(self):\n            self.supabase_url = os.environ.get(\"SUPABASE_URL\")\n            self.supabase_key = os.environ.get(\"SUPABASE_KEY\")\n            self.client = create_client(self.supabase_url, self.supabase_key)\n            self.bucket_name = \"ubs\"\n\n            # Create bucket if it doesn't exist\n            try:\n                self.client.storage.get_bucket(self.bucket_name)\n            except Exception as e:\n                self.client.storage.create_bucket(self.bucket_name)\n\n        def upload_file(self, file_path, file_name=None):\n            \"\"\"Upload a file to Supabase Storage\"\"\"\n            if file_name is None:\n                file_name = os.path.basename(file_path)\n\n            with open(file_path, \"rb\") as f:\n                file_data = f.read()\n\n            return self.upload_binary(file_data, file_name)\n\n        def upload_binary(self, binary_data, file_name):\n            \"\"\"Upload binary data to Supabase Storage\"\"\"\n            # Generate a unique filename to avoid collisions\n            unique_filename = f\"{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}_{file_name}\"\n\n            # Upload to Supabase Storage\n            self.client.storage.from_(self.bucket_name).upload(\n                path=unique_filename,\n                file=binary_data,\n                file_options={\"content-type\": \"application/octet-stream\"}\n            )\n\n            # Get public URL\n            file_url = self.client.storage.from_(self.bucket_name).get_public_url(unique_filename)\n            return file_url\n\n        def save_json_data(self, data, file_name):\n            \"\"\"Save JSON data to Supabase Storage\"\"\"\n            json_str = json.dumps(data, indent=2)\n            return self.upload_binary(json_str.encode('utf-8'), file_name)\n\n    class MarketTypeValidator:\n        \"\"\"Validates if a security is traded on a regulated market or growth market\"\"\"\n\n        def __init__(self, storage_manager):\n            self.storage_manager = storage_manager\n            # Create temp directory for screenshots if it doesn't exist\n            os.makedirs(\"temp\", exist_ok=True)\n\n        async def check_market_type(self, isin: str) -> Tuple[bool, str, str, str]:\n            \"\"\"\n            Check the market type for a given ISIN\n\n            Args:\n                isin: The ISIN to check\n\n            Returns:\n                Tuple containing:\n                - is_regulated: True if traded on a regulated market\n                - market_type: The identified market type\n                - source_url: The URL that was used to get this information\n                - evidence_url: URL to the screenshot evidence in Supabase\n            \"\"\"\n            # First, determine the country from the ISIN\n            country_code = isin[:2]\n\n            if country_code == \"DE\":\n                return await self._check_german_market(isin)\n            elif country_code == \"FR\":\n                return await self._check_french_market(isin)\n            else:\n                # For other countries, we'd add similar methods\n                return None, f\"Unknown market for country {country_code}\", None, None\n\n        async def _check_german_market(self, isin: str) -> Tuple[bool, str, str, str]:\n            \"\"\"\n            Check if a German security is on a regulated market using boerse-frankfurt.de\n            \"\"\"\n            url = f\"https://www.boerse-frankfurt.de/aktie/{isin}\"\n            temp_screenshot_path = f\"temp/evidence_{isin}_german_market_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n\n            async with async_playwright() as p:\n                browser = await p.chromium.launch(proxy={\n                            \"server\": proxy_server,\n                            \"username\": proxy_username,\n                            \"password\": proxy_password\n                        },\n                        headless=True  # Set to True for headless operation\n                    )\n                page = await browser.new_page()\n                evidence_url = None\n\n                try:\n                    await page.goto(url)\n                    await page.wait_for_selector(\".widget-table\", timeout=10000)\n\n                    # Scroll to the bottom of the page to ensure all content is loaded\n                    await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n\n                    # Allow some time for any lazy-loaded content to appear\n                    await asyncio.sleep(1)\n\n                    # Capture screenshot for evidence\n                    await page.screenshot(path=temp_screenshot_path, full_page=True)\n\n                    # Upload screenshot to Supabase\n                    evidence_url = self.storage_manager.upload_file(temp_screenshot_path)\n\n                    # Extract all table rows\n                    rows = await page.query_selector_all(\"table.widget-table tr\")\n\n                    market_type = \"Unknown\"\n                    for row in rows:\n                        cells = await row.query_selector_all(\"td\")\n                        if len(cells) == 2:\n                            key = (await cells[0].inner_text()).strip().lower()\n                            value = (await cells[1].inner_text()).strip().lower()\n\n                            if key == \"markt\":\n                                market_type = value\n                                break\n\n                    is_regulated = \"regulierter markt\" in market_type\n                    pretty_market = \"Regulated Market\" if is_regulated else \"Unregulated Market\" if market_type else \"Unknown Market\"\n                    page_url = page.url\n\n                    # Clean up the temp file\n                    if os.path.exists(temp_screenshot_path):\n                        os.remove(temp_screenshot_path)\n\n                    return is_regulated, pretty_market, page_url, evidence_url\n\n                except Exception as e:\n                    return None, f\"Error checking market: {str(e)}\", url, evidence_url\n\n                finally:\n                    await browser.close()\n\n        async def _check_french_market(self, isin: str) -> Tuple[bool, str, str, str]:\n            \"\"\"Check if a French security is on a regulated market (via Euronext Paris).\"\"\"\n            url = f\"https://live.euronext.com/en/product/equities/{isin}-XPAR/market-information\"\n            temp_screenshot_path = f\"temp/evidence_{isin}_french_market_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n\n            async with async_playwright() as p:\n                browser = await p.chromium.launch()\n                page = await browser.new_page()\n                evidence_url = None\n\n                try:\n                    await page.goto(url)\n                    await page.wait_for_selector(\"div#fs_info_block table\", timeout=15000)\n\n                    # Scroll to the bottom of the page to ensure all content is loaded\n                    await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n\n                    # Allow some time for any lazy-loaded content to appear\n                    await asyncio.sleep(1)\n\n                    # Capture screenshot for evidence\n                    await page.screenshot(path=temp_screenshot_path, full_page=True)\n\n                    # Upload screenshot to Supabase\n                    evidence_url = self.storage_manager.upload_file(temp_screenshot_path)\n\n                    # Get all rows in the General Information table\n                    rows = await page.query_selector_all(\"div#fs_info_block table tr\")\n                    for row in rows:\n                        cells = await row.query_selector_all(\"td\")\n                        if len(cells) >= 2:\n                            key = (await cells[0].inner_text()).strip()\n                            value = (await cells[1].inner_text()).strip()\n                            if key == \"Market\":\n                                is_regulated = value.strip().lower() == \"euronext paris\"\n                                market_type = \"Regulated Market\" if is_regulated else \"Unregulated Market\"\n\n                                # Clean up the temp file\n                                if os.path.exists(temp_screenshot_path):\n                                    os.remove(temp_screenshot_path)\n\n                                return is_regulated, market_type, url, evidence_url\n\n                    # Clean up the temp file\n                    if os.path.exists(temp_screenshot_path):\n                        os.remove(temp_screenshot_path)\n\n                    return None, \"Market info not found\", url, evidence_url\n\n                except Exception as e:\n                    # Clean up the temp file if it exists\n                    if os.path.exists(temp_screenshot_path):\n                        os.remove(temp_screenshot_path)\n                    return None, f\"Error checking market: {str(e)}\", url, evidence_url\n\n                finally:\n                    await browser.close()\n\n    class OutstandingSharesValidator:\n        \"\"\"Validates the outstanding shares for Swiss companies\"\"\"\n\n        def __init__(self, storage_manager):\n            self.storage_manager = storage_manager\n            # Create temp directory for screenshots if it doesn't exist\n            os.makedirs(\"temp\", exist_ok=True)\n\n        async def verify_outstanding_shares(self, company_name: str, expected_shares: int) -> Tuple[bool, int, str, str]:\n            \"\"\"\n            Verify the outstanding shares for a Swiss company\n\n            Args:\n                company_name: The name of the company to check\n                expected_shares: The expected number of outstanding shares\n\n            Returns:\n                Tuple containing:\n                - is_matched: True if the outstanding shares match the expected value\n                - actual_shares: The actual outstanding shares found\n                - source_url: The URL used to obtain this information\n                - evidence_url: URL to the screenshot evidence in Supabase\n            \"\"\"\n            proxy_server = \"pr.rampageproxies.com:8888\"\n            proxy_username = \"xdsmbKbB-cc-ch-pool-rampagecore\"\n            proxy_password = \"FZeZSSFc\"\n            # Zefix search URL\n            zefix_url = \"https://www.zefix.ch/en/search/entity/list/firm/1184151\"\n            temp_screenshot_path = f\"temp/evidence_{company_name.replace(' ', '_')}_shares_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n\n            async with async_playwright() as p:\n                browser = await p.chromium.launch(\n                    headless=True,\n                    args=['--window-size=1920,1080', '--disable-dev-shm-usage']\n                )\n\n                context = await browser.new_context(\n                    viewport={'width': 1920, 'height': 1080},\n                    user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n                )\n\n                page = await context.new_page()\n                evidence_url = None\n                actual_shares = None\n\n                try:\n                    await page.goto(zefix_url)\n\n                    # Wait for page to load completely\n                    await page.wait_for_load_state(\"networkidle\")\n\n                    # Enter company name in the search field\n                    search_input = page.locator('input[formcontrolname=\"mainSearch\"]').first\n                    await search_input.fill(company_name)\n\n                    # Click the search button\n                    search_button = page.locator('button span.mdc-button__label:has-text(\"search\")').first\n                    await search_button.click()\n\n                    # Wait for search results\n                    await page.wait_for_load_state(\"networkidle\")\n\n                    # Initialize variables for our target URL and clean UID\n                    target_url = None\n                    uid_clean = None\n\n                    # First try to find UID directly\n                    uid_selector = 'table.company-info tr th:has-text(\"UID\") + td a'\n\n                    # Try to locate the UID element\n                    uid_found = False\n                    try:\n                        await page.wait_for_selector(uid_selector, state='visible', timeout=10000)\n                        uid_found = True\n                    except Exception as e:\n                        print(f\"UID element not found directly: {e}\")\n\n                    if uid_found:\n                        # Extract UID from the company info table\n                        uid_element = page.locator(uid_selector).first\n\n                        if uid_element:\n                            uid_text = await uid_element.inner_text()\n                            # Extract the UID (format: CHE-XXX.XXX.XXX) and clean it\n                            uid_match = re.search(r'(CHE-[0-9]{3}\\.[0-9]{3}\\.[0-9]{3})', uid_text)\n                            if uid_match:\n                                uid_clean = uid_match.group(1)\n\n                                # Generate target URL with the cleaned UID\n                                target_url = f\"https://zh.chregister.ch/cr-portal/auszug/auszug.xhtml?uid={uid_clean}\"\n\n                    # If UID was not found or could not be extracted, try the alternative approach with the table\n                    if not target_url:\n                        # Look for the cantonal excerpt button in the search results table\n                        cantonal_excerpt_button = page.locator('a.ob-button:has-text(\"cantonal excerpt\")').first\n\n                        if cantonal_excerpt_button:\n                            # Get the href attribute which contains the target URL\n                            target_url = await cantonal_excerpt_button.get_attribute(\"href\")\n\n\n                    # If we still don't have a target URL, we can't proceed\n                    if not target_url:\n                        print(\"Could not find UID or cantonal excerpt link in search results\")\n                        return False, None, zefix_url, None\n\n                    await browser.close()\n\n                    # Now launch a new browser with proxy for accessing the target URL\n                    # browser = await p.chromium.launch(\n                    #     proxy={\n                    #         \"server\": proxy_server,\n                    #         \"username\": proxy_username,\n                    #         \"password\": proxy_password\n                    #     },\n                    #     headless=False  # Set to True for headless operation\n                    # )\n                    browserless_api_key = \"2SImgKoOPRBT1h75fe37ca22e1308e6ec2325597c700924cf\"\n                    browserless_url = f\"wss://chrome.browserless.io?token={browserless_api_key}\"\n                    browser = await p.chromium.connect_over_cdp(browserless_url)\n                    page = await browser.new_page()\n\n                    # Navigate to the target URL\n                    await page.goto(target_url)\n\n                    # Wait for page to load completely\n                    await page.wait_for_load_state(\"networkidle\")\n\n                    # Take a screenshot for evidence\n                    await page.screenshot(path=temp_screenshot_path, full_page=True)\n\n                    # Upload screenshot to Supabase\n                    evidence_url = self.storage_manager.upload_file(temp_screenshot_path)\n\n                    # Check if the table with \"Denomination of shares\" exists\n                    has_denomination_column = await page.locator('th:has-text(\"Denomination of shares\")').count() > 0\n\n                    if has_denomination_column:\n                        # Get all non-strikethrough denomination values\n                        denomination_elements = await page.locator('tr.evenRowHideAndSeek td:nth-child(5) span span:not(.strike)').all()\n\n                        # If not found, try the alternative selector\n                        if not denomination_elements:\n                            denomination_elements = await page.locator('table tr:last-child td:nth-child(5) span span:not(.strike)').all()\n\n                        # If still not found, try a more general selector\n                        if not denomination_elements:\n                            denomination_elements = await page.locator('table td:has-text(\"\\'\") span:not(.strike)').all()\n\n                        # Get text from all elements\n                        denomination_texts = []\n                        for element in denomination_elements:\n                            text = await element.inner_text()\n                            denomination_texts.append(text)\n\n                        # Extract numbers from all texts and sum them up\n                        total_denomination = 0\n                        for text in denomination_texts:\n                            # Extract numbers using regex - looking for patterns like 1'240'835 or 1'655'000\n                            match = re.search(r\"(\\d[\\d']*)\", text)\n                            if match:\n                                # Get the number and remove apostrophes\n                                number_str = match.group(1).replace(\"'\", \"\")\n                                try:\n                                    number = int(number_str)\n                                    total_denomination += number\n                                except ValueError:\n                                    print(f\"Could not convert {number_str} to integer\")\n\n                        if total_denomination > 0:\n                            actual_shares = total_denomination\n\n                    # Clean up the temp file\n                    if os.path.exists(temp_screenshot_path):\n                        os.remove(temp_screenshot_path)\n\n                    # Compare with expected shares\n                    is_matched = False\n                    if actual_shares is not None:\n                        is_matched = (actual_shares == expected_shares)\n\n                    return is_matched, actual_shares, target_url, evidence_url\n\n                except Exception as e:\n                    if os.path.exists(temp_screenshot_path):\n                        os.remove(temp_screenshot_path)\n                    return False, None, zefix_url, evidence_url\n\n                finally:\n                    await browser.close()\n\n    class AlertProcessingSystem:\n        def __init__(self):\n            self.results = []\n            self.storage_manager = SupabaseStorage()\n\n        def load_csv_data(self, csv_url):\n            \"\"\"Load CSV data from URL with robust encoding handling\"\"\"\n            try:\n                # Check if it's a URL or local file\n                if csv_url.startswith('http'):\n                    # Download the file from URL\n                    response = requests.get(csv_url)\n                    if response.status_code == 200:\n                        # Check if Excel or CSV\n                        if csv_url.endswith('.xlsx') or csv_url.endswith('.xls'):\n                            return pd.read_excel(BytesIO(response.content))\n                        else:\n                            # Try different encodings\n                            encodings = ['utf-8', 'latin1', 'iso-8859-1', 'cp1252']\n\n                            for encoding in encodings:\n                                try:\n                                    return pd.read_csv(BytesIO(response.content), encoding=encoding, engine='python')\n                                except UnicodeDecodeError:\n                                    continue\n\n                            return pd.read_csv(BytesIO(response.content), encoding='latin1', errors='replace', engine='python')\n                    else:\n                        raise Exception(f\"Failed to download file: {response.status_code}\")\n                else:\n                    # Check if Excel or CSV\n                    if csv_url.endswith('.xlsx') or csv_url.endswith('.xls'):\n                        return pd.read_excel(csv_url)\n                    else:\n                        # Try different encodings\n                        encodings = ['utf-8', 'latin1', 'iso-8859-1', 'cp1252']\n\n                        for encoding in encodings:\n                            try:\n                                return pd.read_csv(csv_url, encoding=encoding, engine='python')\n                            except UnicodeDecodeError:\n                                continue\n\n                        return pd.read_csv(csv_url, encoding='latin1', errors='replace', engine='python')\n            except Exception as e:\n                raise\n\n        async def verify_market_type(self, isin, alert_id):\n            \"\"\"Verify market type for a security\"\"\"\n            validator = MarketTypeValidator(self.storage_manager)\n            is_regulated, market_type, source_url, evidence_url = await validator.check_market_type(isin)\n\n            # Return verification results\n            return {\n                \"alert_id\": alert_id,\n                \"isin\": isin,\n                \"is_regulated\": is_regulated,\n                \"market_type\": market_type,\n                \"source_url\": source_url,\n                \"evidence_url\": evidence_url,\n                \"verification_timestamp\": datetime.datetime.now().isoformat()\n            }\n\n        async def verify_swiss_shares(self, company_name, expected_shares, alert_id, isin):\n            \"\"\"Verify outstanding shares for a Swiss company\"\"\"\n            validator = OutstandingSharesValidator(self.storage_manager)\n            is_matched, actual_shares, source_url, evidence_url = await validator.verify_outstanding_shares(company_name, expected_shares)\n\n            # Return verification results\n            return {\n                \"alert_id\": alert_id,\n                \"isin\": isin,\n                \"company_name\": company_name,\n                \"is_matched\": is_matched,\n                \"expected_shares\": expected_shares,\n                \"actual_shares\": actual_shares,\n                \"source_url\": source_url,\n                \"evidence_url\": evidence_url,\n                \"verification_timestamp\": datetime.datetime.now().isoformat()\n            }\n\n        def make_final_decision(self, verification_result, is_swiss=False):\n            \"\"\"Make final decision based on verification results\"\"\"\n            if is_swiss:\n                # For Swiss companies, use shares matching\n                is_matched = verification_result.get(\"is_matched\")\n                expected_shares = verification_result.get(\"expected_shares\")\n                actual_shares = verification_result.get(\"actual_shares\")\n\n                if is_matched is None or actual_shares is None:\n                    decision = \"Inconclusive\"\n                    justification = \"Could not determine outstanding shares\"\n                elif is_matched:\n                    decision = \"True Positive\"\n                    justification = f\"Outstanding shares match: Expected={expected_shares}, Actual={actual_shares}\"\n                else:\n                    decision = \"False Positive\"\n                    justification = f\"Outstanding shares mismatch: Expected={expected_shares}, Actual={actual_shares}\"\n            else:\n                # For non-Swiss companies, use market type\n                is_regulated = verification_result.get(\"is_regulated\")\n\n                if is_regulated is None:\n                    decision = \"Inconclusive\"\n                    justification = \"Could not determine market type\"\n                elif is_regulated:\n                    decision = \"True Positive\"\n                    justification = f\"Security is traded on a regulated market: {verification_result.get('market_type')}\"\n                else:\n                    decision = \"False Positive\"\n                    justification = f\"Security is traded on an unregulated market: {verification_result.get('market_type')}\"\n\n            return {\n                \"decision\": decision,\n                \"justification\": justification,\n                \"timestamp\": datetime.datetime.now().isoformat()\n            }\n\n        def export_results(self):\n            \"\"\"Export processing results to Supabase in a human-readable format\"\"\"\n            if self.results:\n                # Create a more human-readable format with the most relevant fields\n                readable_results = []\n                for result in self.results:\n                    verification = result.get(\"verification\", {})\n                    decision = result.get(\"decision\", {})\n\n                    readable_result = {\n                        \"alert_id\": result.get(\"alert_id\"),\n                        \"isin\": result.get(\"isin\"),\n                        \"company_name\": result.get(\"company_name\"),\n                        \"source_url\": verification.get(\"source_url\", \"\"),\n                        \"evidence_url\": verification.get(\"evidence_url\", \"\"),\n                        \"verification_timestamp\": verification.get(\"verification_timestamp\", \"\"),\n                        \"decision\": decision.get(\"decision\", \"Unknown\"),\n                        \"justification\": decision.get(\"justification\", \"\")\n                    }\n                    readable_results.append(readable_result)\n\n                # Convert to DataFrame\n                df = pd.DataFrame(readable_results)\n\n                # Save to CSV in memory\n                csv_buffer = BytesIO()\n                df.to_csv(csv_buffer, index=False)\n                csv_buffer.seek(0)\n\n                # Save CSV to Supabase\n                results_filename = f\"alert_processing_results_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n                results_url = self.storage_manager.upload_binary(csv_buffer.getvalue(), results_filename)\n\n                return {\n                    \"csv_url\": results_url,\n                    \"record_count\": len(readable_results)\n                }\n            else:\n                return None\n\n    # Process the alerts\n    async def process_alerts(csv_url):\n        # Initialize the alert processing system\n        aps = AlertProcessingSystem()\n\n        # Load data\n        data = aps.load_csv_data(csv_url)\n\n        # Process each alert\n        results = []\n        for _, row in data.iterrows():\n            alert_id = row['Alert ID']\n            isin = row['ISIN']\n            company_name = row['Company Name']\n\n            # Check if it's a Swiss company by the ISIN code (starts with 'CH')\n            is_swiss = isin.startswith('CH')\n\n            if is_swiss:\n                # For Swiss companies, verify outstanding shares\n                if 'Outstanding Shares' in row and pd.notna(row['Outstanding Shares']):\n                    expected_shares = int(row['Outstanding Shares'])\n                    verification = await aps.verify_swiss_shares(company_name, expected_shares, alert_id, isin)\n                    verification_type = \"outstanding_shares\"\n                else:\n                    verification = {\n                        \"alert_id\": alert_id,\n                        \"isin\": isin,\n                        \"company_name\": company_name,\n                        \"is_matched\": None,\n                        \"expected_shares\": None,\n                        \"actual_shares\": None,\n                        \"source_url\": None,\n                        \"evidence_url\": None,\n                        \"verification_timestamp\": datetime.datetime.now().isoformat()\n                    }\n                    verification_type = \"outstanding_shares\"\n            else:\n                # For non-Swiss companies, verify market type\n                verification = await aps.verify_market_type(isin, alert_id)\n                verification_type = \"market_type\"\n\n            # Decision making\n            decision = aps.make_final_decision(verification, is_swiss=is_swiss)\n\n            # Add to results\n            if is_swiss:\n                result = {\n                    \"alert_id\": alert_id,\n                    \"isin\": isin,\n                    \"company_name\": company_name,\n                    \"is_matched\": verification.get(\"is_matched\"),\n                    \"expected_shares\": verification.get(\"expected_shares\"),\n                    \"actual_shares\": verification.get(\"actual_shares\"),\n                    \"decision\": decision.get(\"decision\"),\n                    \"justification\": decision.get(\"justification\"),\n                    \"evidence_url\": verification.get(\"evidence_url\"),\n                    \"source_url\": verification.get(\"source_url\"),\n                }\n            else:\n                result = {\n                    \"alert_id\": alert_id,\n                    \"isin\": isin,\n                    \"company_name\": company_name,\n                    \"market_type\": verification.get(\"market_type\"),\n                    \"is_regulated\": verification.get(\"is_regulated\"),\n                    \"decision\": decision.get(\"decision\"),\n                    \"justification\": decision.get(\"justification\"),\n                    \"evidence_url\": verification.get(\"evidence_url\"),\n                    \"source_url\": verification.get(\"source_url\"),\n                }\n            results.append(result)\n\n        # Export results\n        output_info = aps.export_results()\n\n        return {\n            \"completed\": True,\n            \"alerts_processed\": len(results),\n            \"results\": results,\n            \"output_files\": output_info\n        }\n\n    try:\n        processing_results = await process_alerts(csv_url)\n        return f\"\"\"\nAlert processing completed successfully.\n- Processed {processing_results['alerts_processed']} alerts\n- Results exported to:\n  - CSV: {processing_results['output_files']['csv_url']}\n- Detailed evidence and reports saved in Supabase\n\"\"\"\n    except Exception as e:\n        return f\"Error processing alerts: {str(e)}\"\n","name":"process_group_alert","description":"\n    Process alerts from the CSV file.\n    \n    Args:\n        csv_url: URL or path to the CSV file\n        \n    Returns:\n        Processing results summary\n    ","global_imports":[],"has_cancellation_support":false}},{"provider":"autogen_core.tools.FunctionTool","component_type":"tool","version":1,"component_version":1,"description":"Create custom tools by wrapping standard Python functions.","label":"FunctionTool","config":{"source_code":"async def process_individual_alert(isin: str, company_name: str, outstanding_shares: int = None) -> str:\n    \"\"\"\n    Process a single alert for a company.\n\n    Args:\n        isin: International Securities Identification Number for the security\n        company_name: Name of the company\n        outstanding_shares: Number of outstanding shares (required for Swiss companies)\n\n    Returns:\n        Processing results summary\n    \"\"\"\n    from playwright.async_api import async_playwright\n    from io import BytesIO\n    import requests\n    import datetime\n    import logging\n    import pandas as pd\n    from typing import Tuple, Dict, List\n    from supabase import create_client, Client\n    import json\n    import os\n    import re\n\n    proxy_server = \"pr.rampageproxies.com:8888\"\n    proxy_username = \"xdsmbKbB-cc-ch-pool-rampagecore\"\n    proxy_password = \"FZeZSSFc\"\n\n    class SupabaseStorage:\n        def __init__(self):\n            self.supabase_url = os.environ.get(\"SUPABASE_URL\")\n            self.supabase_key = os.environ.get(\"SUPABASE_KEY\")\n            self.client = create_client(self.supabase_url, self.supabase_key)\n            self.bucket_name = \"ubs\"\n\n            # Create bucket if it doesn't exist\n            try:\n                self.client.storage.get_bucket(self.bucket_name)\n            except Exception as e:\n                self.client.storage.create_bucket(self.bucket_name)\n\n        def upload_file(self, file_path, file_name=None):\n            \"\"\"Upload a file to Supabase Storage\"\"\"\n            if file_name is None:\n                file_name = os.path.basename(file_path)\n\n            with open(file_path, \"rb\") as f:\n                file_data = f.read()\n\n            return self.upload_binary(file_data, file_name)\n\n        def upload_binary(self, binary_data, file_name):\n            \"\"\"Upload binary data to Supabase Storage\"\"\"\n            # Generate a unique filename to avoid collisions\n            unique_filename = f\"{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}_{file_name}\"\n\n            # Upload to Supabase Storage\n            self.client.storage.from_(self.bucket_name).upload(\n                path=unique_filename,\n                file=binary_data,\n                file_options={\"content-type\": \"application/octet-stream\"}\n            )\n\n            # Get public URL\n            file_url = self.client.storage.from_(self.bucket_name).get_public_url(unique_filename)\n            return file_url\n\n        def save_json_data(self, data, file_name):\n            \"\"\"Save JSON data to Supabase Storage\"\"\"\n            json_str = json.dumps(data, indent=2)\n            return self.upload_binary(json_str.encode('utf-8'), file_name)\n\n    class MarketTypeValidator:\n        \"\"\"Validates if a security is traded on a regulated market or growth market\"\"\"\n\n        def __init__(self, storage_manager):\n            self.storage_manager = storage_manager\n            # Create temp directory for screenshots if it doesn't exist\n            os.makedirs(\"temp\", exist_ok=True)\n\n        async def check_market_type(self, isin: str) -> Tuple[bool, str, str, str]:\n            \"\"\"\n            Check the market type for a given ISIN\n\n            Args:\n                isin: The ISIN to check\n\n            Returns:\n                Tuple containing:\n                - is_regulated: True if traded on a regulated market\n                - market_type: The identified market type\n                - source_url: The URL that was used to get this information\n                - evidence_url: URL to the screenshot evidence in Supabase\n            \"\"\"\n            # First, determine the country from the ISIN\n            country_code = isin[:2]\n\n            if country_code == \"DE\":\n                return await self._check_german_market(isin)\n            elif country_code == \"FR\":\n                return await self._check_french_market(isin)\n            else:\n                # For other countries, we'd add similar methods\n                return None, f\"Unknown market for country {country_code}\", None, None\n\n        async def _check_german_market(self, isin: str) -> Tuple[bool, str, str, str]:\n            \"\"\"\n            Check if a German security is on a regulated market using boerse-frankfurt.de\n            \"\"\"\n            url = f\"https://www.boerse-frankfurt.de/aktie/{isin}\"\n            temp_screenshot_path = f\"temp/evidence_{isin}_german_market_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n\n            async with async_playwright() as p:\n                browser = await p.chromium.launch(proxy={\n                            \"server\": proxy_server,\n                            \"username\": proxy_username,\n                            \"password\": proxy_password\n                        },\n                        headless=True  # Set to True for headless operation\n                    )\n                page = await browser.new_page()\n                evidence_url = None\n\n                try:\n                    await page.goto(url)\n                    await page.wait_for_selector(\".widget-table\", timeout=10000)\n\n                    # Scroll to the bottom of the page to ensure all content is loaded\n                    await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n\n                    # Allow some time for any lazy-loaded content to appear\n                    await asyncio.sleep(1)\n\n                    # Capture screenshot for evidence\n                    await page.screenshot(path=temp_screenshot_path, full_page=True)\n\n                    # Upload screenshot to Supabase\n                    evidence_url = self.storage_manager.upload_file(temp_screenshot_path)\n\n                    # Extract all table rows\n                    rows = await page.query_selector_all(\"table.widget-table tr\")\n\n                    market_type = \"Unknown\"\n                    for row in rows:\n                        cells = await row.query_selector_all(\"td\")\n                        if len(cells) == 2:\n                            key = (await cells[0].inner_text()).strip().lower()\n                            value = (await cells[1].inner_text()).strip().lower()\n\n                            if key == \"markt\":\n                                market_type = value\n                                break\n\n                    is_regulated = \"regulierter markt\" in market_type\n                    pretty_market = \"Regulated Market\" if is_regulated else \"Unregulated Market\" if market_type else \"Unknown Market\"\n                    page_url = page.url\n\n                    # Clean up the temp file\n                    if os.path.exists(temp_screenshot_path):\n                        os.remove(temp_screenshot_path)\n\n                    return is_regulated, pretty_market, page_url, evidence_url\n\n                except Exception as e:\n                    return None, f\"Error checking market: {str(e)}\", url, evidence_url\n\n                finally:\n                    await browser.close()\n\n        async def _check_french_market(self, isin: str) -> Tuple[bool, str, str, str]:\n            \"\"\"Check if a French security is on a regulated market (via Euronext Paris).\"\"\"\n            url = f\"https://live.euronext.com/en/product/equities/{isin}-XPAR/market-information\"\n            temp_screenshot_path = f\"temp/evidence_{isin}_french_market_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n\n            async with async_playwright() as p:\n                browser = await p.chromium.launch()\n                page = await browser.new_page()\n                evidence_url = None\n\n                try:\n                    await page.goto(url)\n                    await page.wait_for_selector(\"div#fs_info_block table\", timeout=15000)\n\n                    # Scroll to the bottom of the page to ensure all content is loaded\n                    await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n\n                    # Allow some time for any lazy-loaded content to appear\n                    await asyncio.sleep(1)\n\n                    # Capture screenshot for evidence\n                    await page.screenshot(path=temp_screenshot_path, full_page=True)\n\n                    # Upload screenshot to Supabase\n                    evidence_url = self.storage_manager.upload_file(temp_screenshot_path)\n\n                    # Get all rows in the General Information table\n                    rows = await page.query_selector_all(\"div#fs_info_block table tr\")\n                    for row in rows:\n                        cells = await row.query_selector_all(\"td\")\n                        if len(cells) >= 2:\n                            key = (await cells[0].inner_text()).strip()\n                            value = (await cells[1].inner_text()).strip()\n                            if key == \"Market\":\n                                is_regulated = value.strip().lower() == \"euronext paris\"\n                                market_type = \"Regulated Market\" if is_regulated else \"Unregulated Market\"\n\n                                # Clean up the temp file\n                                if os.path.exists(temp_screenshot_path):\n                                    os.remove(temp_screenshot_path)\n\n                                return is_regulated, market_type, url, evidence_url\n\n                    # Clean up the temp file\n                    if os.path.exists(temp_screenshot_path):\n                        os.remove(temp_screenshot_path)\n\n                    return None, \"Market info not found\", url, evidence_url\n\n                except Exception as e:\n                    # Clean up the temp file if it exists\n                    if os.path.exists(temp_screenshot_path):\n                        os.remove(temp_screenshot_path)\n                    return None, f\"Error checking market: {str(e)}\", url, evidence_url\n\n                finally:\n                    await browser.close()\n\n    class OutstandingSharesValidator:\n        \"\"\"Validates the outstanding shares for Swiss companies\"\"\"\n\n        def __init__(self, storage_manager):\n            self.storage_manager = storage_manager\n            # Create temp directory for screenshots if it doesn't exist\n            os.makedirs(\"temp\", exist_ok=True)\n\n        async def verify_outstanding_shares(self, company_name: str, expected_shares: int) -> Tuple[bool, int, str, str]:\n            \"\"\"\n            Verify the outstanding shares for a Swiss company\n\n            Args:\n                company_name: The name of the company to check\n                expected_shares: The expected number of outstanding shares\n\n            Returns:\n                Tuple containing:\n                - is_matched: True if the outstanding shares match the expected value\n                - actual_shares: The actual outstanding shares found\n                - source_url: The URL used to obtain this information\n                - evidence_url: URL to the screenshot evidence in Supabase\n            \"\"\"\n            proxy_server = \"pr.rampageproxies.com:8888\"\n            proxy_username = \"xdsmbKbB-cc-ch-pool-rampagecore\"\n            proxy_password = \"FZeZSSFc\"\n            # Zefix search URL\n            zefix_url = \"https://www.zefix.ch/en/search/entity/list/firm/1184151\"\n            temp_screenshot_path = f\"temp/evidence_{company_name.replace(' ', '_')}_shares_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n\n            async with async_playwright() as p:\n                browser = await p.chromium.launch(\n                    headless=True,\n                    args=['--window-size=1920,1080', '--disable-dev-shm-usage']\n                )\n\n                context = await browser.new_context(\n                    viewport={'width': 1920, 'height': 1080},\n                    user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n                )\n\n                page = await context.new_page()\n                evidence_url = None\n                actual_shares = None\n\n                try:\n                    await page.goto(zefix_url)\n\n                    # Wait for page to load completely\n                    await page.wait_for_load_state(\"networkidle\")\n\n                    # Enter company name in the search field\n                    search_input = page.locator('input[formcontrolname=\"mainSearch\"]').first\n                    await search_input.fill(company_name)\n\n                    # Click the search button\n                    search_button = page.locator('button span.mdc-button__label:has-text(\"search\")').first\n                    await search_button.click()\n\n                    # Wait for search results\n                    await page.wait_for_load_state(\"networkidle\")\n\n                    # Initialize variables for our target URL and clean UID\n                    target_url = None\n                    uid_clean = None\n\n                    # First try to find UID directly\n                    uid_selector = 'table.company-info tr th:has-text(\"UID\") + td a'\n\n                    # Try to locate the UID element\n                    uid_found = False\n                    try:\n                        await page.wait_for_selector(uid_selector, state='visible', timeout=30000)\n                        uid_found = True\n                    except Exception as e:\n                        print(f\"UID element not found directly: {e}\")\n\n                    if uid_found:\n                        # Extract UID from the company info table\n                        uid_element = page.locator(uid_selector).first\n\n                        if uid_element:\n                            uid_text = await uid_element.inner_text()\n                            # Extract the UID (format: CHE-XXX.XXX.XXX) and clean it\n                            uid_match = re.search(r'(CHE-[0-9]{3}\\.[0-9]{3}\\.[0-9]{3})', uid_text)\n                            if uid_match:\n                                uid_clean = uid_match.group(1)\n\n                                # Generate target URL with the cleaned UID\n                                target_url = f\"https://zh.chregister.ch/cr-portal/auszug/auszug.xhtml?uid={uid_clean}\"\n\n                    # If UID was not found or could not be extracted, try the alternative approach with the table\n                    if not target_url:\n                        # Look for the cantonal excerpt button in the search results table\n                        cantonal_excerpt_button = page.locator('a.ob-button:has-text(\"cantonal excerpt\")').first\n\n                        if cantonal_excerpt_button:\n                            # Get the href attribute which contains the target URL\n                            target_url = await cantonal_excerpt_button.get_attribute(\"href\")\n\n\n                    # If we still don't have a target URL, we can't proceed\n                    if not target_url:\n                        print(\"Could not find UID or cantonal excerpt link in search results\")\n                        return False, None, zefix_url, None\n\n                    await browser.close()\n\n                    # Now launch a new browser with proxy for accessing the target URL\n                    # browser = await p.chromium.launch(\n                    #     proxy={\n                    #         \"server\": proxy_server,\n                    #         \"username\": proxy_username,\n                    #         \"password\": proxy_password\n                    #     },\n                    #     headless=False  # Set to True for headless operation\n                    # )\n                    browserless_api_key = \"2SImgKoOPRBT1h75fe37ca22e1308e6ec2325597c700924cf\"\n                    browserless_url = f\"wss://chrome.browserless.io?token={browserless_api_key}\"\n                    browser = await p.chromium.connect_over_cdp(browserless_url)\n                    page = await browser.new_page()\n\n                    # Navigate to the target URL\n                    await page.goto(target_url)\n\n                    # Wait for page to load completely\n                    await page.wait_for_load_state(\"networkidle\")\n\n                    # Take a screenshot for evidence\n                    await page.screenshot(path=temp_screenshot_path, full_page=True)\n\n                    # Upload screenshot to Supabase\n                    evidence_url = self.storage_manager.upload_file(temp_screenshot_path)\n\n                    # Check if the table with \"Denomination of shares\" exists\n                    has_denomination_column = await page.locator('th:has-text(\"Denomination of shares\")').count() > 0\n\n                    if has_denomination_column:\n                        # Get all non-strikethrough denomination values\n                        denomination_elements = await page.locator('tr.evenRowHideAndSeek td:nth-child(5) span span:not(.strike)').all()\n\n                        # If not found, try the alternative selector\n                        if not denomination_elements:\n                            denomination_elements = await page.locator('table tr:last-child td:nth-child(5) span span:not(.strike)').all()\n\n                        # If still not found, try a more general selector\n                        if not denomination_elements:\n                            denomination_elements = await page.locator('table td:has-text(\"\\'\") span:not(.strike)').all()\n\n                        # Get text from all elements\n                        denomination_texts = []\n                        for element in denomination_elements:\n                            text = await element.inner_text()\n                            denomination_texts.append(text)\n\n                        # Extract numbers from all texts and sum them up\n                        total_denomination = 0\n                        for text in denomination_texts:\n                            # Extract numbers using regex - looking for patterns like 1'240'835 or 1'655'000\n                            match = re.search(r\"(\\d[\\d']*)\", text)\n                            if match:\n                                # Get the number and remove apostrophes\n                                number_str = match.group(1).replace(\"'\", \"\")\n                                try:\n                                    number = int(number_str)\n                                    total_denomination += number\n                                except ValueError:\n                                    print(f\"Could not convert {number_str} to integer\")\n\n                        if total_denomination > 0:\n                            actual_shares = total_denomination\n\n                    # Clean up the temp file\n                    if os.path.exists(temp_screenshot_path):\n                        os.remove(temp_screenshot_path)\n\n                    # Compare with expected shares\n                    is_matched = False\n                    if actual_shares is not None:\n                        is_matched = (actual_shares == expected_shares)\n\n                    return is_matched, actual_shares, target_url, evidence_url\n\n                except Exception as e:\n                    if os.path.exists(temp_screenshot_path):\n                        os.remove(temp_screenshot_path)\n                    return False, None, zefix_url, evidence_url\n\n                finally:\n                    await browser.close()\n\n    # Process the alert\n    try:\n        # Initialize storage manager\n        storage_manager = SupabaseStorage()\n\n        # Generate a unique alert ID\n        alert_id = f\"MANUAL_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}\"\n\n        # Check if it's a Swiss company by the ISIN code (starts with 'CH')\n        is_swiss = isin.startswith('CH')\n\n        # Verification result object\n        verification = None\n        verification_type = None\n\n        if is_swiss:\n            # For Swiss companies, verify outstanding shares\n            if outstanding_shares is not None:\n                validator = OutstandingSharesValidator(storage_manager)\n                is_matched, actual_shares, source_url, evidence_url = await validator.verify_outstanding_shares(company_name, outstanding_shares)\n\n                verification = {\n                    \"alert_id\": alert_id,\n                    \"isin\": isin,\n                    \"company_name\": company_name,\n                    \"is_matched\": is_matched,\n                    \"expected_shares\": outstanding_shares,\n                    \"actual_shares\": actual_shares,\n                    \"source_url\": source_url,\n                    \"evidence_url\": evidence_url,\n                    \"verification_timestamp\": datetime.datetime.now().isoformat()\n                }\n                verification_type = \"outstanding_shares\"\n            else:\n                return f\"Error: Outstanding shares must be provided for Swiss companies (ISIN: {isin})\"\n        else:\n            # For non-Swiss companies, verify market type\n            validator = MarketTypeValidator(storage_manager)\n            is_regulated, market_type, source_url, evidence_url = await validator.check_market_type(isin)\n\n            verification = {\n                \"alert_id\": alert_id,\n                \"isin\": isin,\n                \"company_name\": company_name,\n                \"is_regulated\": is_regulated,\n                \"market_type\": market_type,\n                \"source_url\": source_url,\n                \"evidence_url\": evidence_url,\n                \"verification_timestamp\": datetime.datetime.now().isoformat()\n            }\n            verification_type = \"market_type\"\n\n        # Decision making\n        if is_swiss:\n            # For Swiss companies, use shares matching\n            is_matched = verification.get(\"is_matched\")\n            expected_shares = verification.get(\"expected_shares\")\n            actual_shares = verification.get(\"actual_shares\")\n\n            if is_matched is None or actual_shares is None:\n                decision = \"Inconclusive\"\n                justification = \"Could not determine outstanding shares\"\n            elif is_matched:\n                decision = \"True Positive\"\n                justification = f\"Outstanding shares match: Expected={expected_shares}, Actual={actual_shares}\"\n            else:\n                decision = \"False Positive\"\n                justification = f\"Outstanding shares mismatch: Expected={expected_shares}, Actual={actual_shares}\"\n        else:\n            # For non-Swiss companies, use market type\n            is_regulated = verification.get(\"is_regulated\")\n\n            if is_regulated is None:\n                decision = \"Inconclusive\"\n                justification = \"Could not determine market type\"\n            elif is_regulated:\n                decision = \"True Positive\"\n                justification = f\"Security is traded on a regulated market: {verification.get('market_type')}\"\n            else:\n                decision = \"False Positive\"\n                justification = f\"Security is traded on an unregulated market: {verification.get('market_type')}\"\n\n        # Final processing\n        result = {\n            \"alert_id\": alert_id,\n            \"isin\": isin,\n            \"company_name\": company_name,\n            \"verification_type\": verification_type,\n            \"decision\": decision,\n            \"justification\": justification,\n            \"evidence_url\": verification.get(\"evidence_url\"),\n            \"source_url\": verification.get(\"source_url\"),\n        }\n\n\n        # Return a human-readable summary\n        return f\"\"\"\nIndividual alert processing completed successfully:\n\nAlert Details:\n- ISIN: {isin}\n- Company: {company_name}\n\nVerification Results:\n- Decision: {decision}\n- Justification: {justification}\n{\"- Expected Shares: \" + str(outstanding_shares) if is_swiss else \"\"}\n{\"- Actual Shares: \" + str(actual_shares) if is_swiss and actual_shares is not None else \"\"}\n{\"- Market Type: \" + verification.get(\"market_type\") if not is_swiss else \"\"}\n\nEvidence:\n- Source URL: {verification.get(\"source_url\")}\n- Evidence Screenshot: {verification.get(\"evidence_url\")}\n\"\"\"\n    except Exception as e:\n        return f\"Error processing individual alert: {str(e)}\"\n","name":"process_individual_alert","description":"\n    Process a single alert for a company.\n    \n    Args:\n        isin: International Securities Identification Number for the security\n        company_name: Name of the company\n        outstanding_shares: Number of outstanding shares (required for Swiss companies)\n        \n    Returns:\n        Processing results summary\n    ","global_imports":[],"has_cancellation_support":false}}],"model_context":{"provider":"autogen_core.model_context.UnboundedChatCompletionContext","component_type":"chat_completion_context","version":1,"component_version":1,"description":"An unbounded chat completion context that keeps a view of the all the messages.","label":"UnboundedChatCompletionContext","config":{}},"description":"An agent that provides assistance with ability to use tools.","system_message":"You are a Financial Securities Validation Assistant that helps compliance teams verify market alerts.Always try to introduce yourself.\n\n## Your Expertise\nYou determine if securities alerts are true positives or false positives by:\n\n1. For non-Swiss securities:\n   - Checking if they trade on regulated markets (true positive) vs. unregulated/growth markets (false positive)\n   - Using official stock exchange websites to validate market status\n\n2. For Swiss securities: \n   - Verifying if the outstanding shares match expected values\n   - Using Swiss company registries to validate share counts\n\n## Your Capabilities\nYou can process securities in two ways:\n\n1. Individual Verification:\n   - Requires: ISIN, company name, and for Swiss companies (ISIN starts with 'CH') only need outstanding shares\n   - Use the process_individual_alert tool with these parameters\n\n2. Batch Processing:\n   - Process multiple securities from a CSV file\n   - Requires a URL or path to a CSV containing Alert ID, ISIN, Company Name, and Outstanding Shares (for Swiss companies)\n   - Use the process_group_alert tool with the CSV URL/path\n\n## How You Work\nFor each verification, you:\n1. Capture evidence (screenshots)\n2. Document source URLs\n3. Make a decision (True Positive, False Positive, or Inconclusive)\n4. Provide clear justification for the decision\n5. Store all evidence and reports in Supabase\n\n## Interaction Guidelines\n- Always get complete information before processing\n- For Swiss companies (ISIN starts with 'CH'), verify outstanding shares were provided\n- For batch processing, ensure the CSV file is accessible\n- Present results clearly showing the decision and evidence\n- If you need additional information, ask specific questions\n\nAlways confirm you have all required information before processing a request. If any required data is missing, politely ask for it.","model_client_stream":false,"reflect_on_tool_use":false,"tool_call_summary_format":"{result}","metadata":{}}},{"provider":"autogen_agentchat.agents.UserProxyAgent","component_type":"agent","version":1,"component_version":1,"description":"An agent that can represent a human user through an input function.","label":"UserProxyAgent","config":{"name":"user","description":"A human user"}}],"termination_condition":{"provider":"autogen_agentchat.conditions.TextMentionTermination","component_type":"termination","version":1,"component_version":1,"description":"Terminate the conversation if a specific text is mentioned.","label":"TextMentionTermination","config":{"text":"APPROVE"}},"emit_team_events":false}}